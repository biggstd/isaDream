'''A data model class for IDREAM Drupal Content Nodes.

This module provides the needed utilities to convert an json file to a pandas
dataframe for use in a Bokeh visualization application.

Attributes:
    BASE_PATH (str): The base-path that will be prepended to the filenames
        specified in the .json metadata.

'''

# Generic Python imports.
import os
import json
import itertools
import collections

# Data science imports.
import pandas as pd

# Local package imports.
from .utils import normalize, BASE_PATH


class DrupalNode:
    '''The Study model generated for a single Drupal Node.

    Each Drupal content node for a given experiment is modeled under the same
    `.json` structure.

    There are sub-groups to this structure:
        1. **Node information**: Information concerning the Drupal Node, and
           the overall experiment description and title.
        2. **Study Factors**: Experimental data that applies to all the data
           contained by this node.
        3. **Node Samples**: Experimental materials that apply to all data
           contained within this node.
        4. **Assays**: Individual datafiles and their associated factors.
        5. **Commments**: Commments that apply to this entire Node.

    The atomic units of this model are:
        + **Factors**: Any quantitative or qualitative value. There are several
          subtypes of Factors. They are named differently only for the purposes
          of working with Drupal fields (and perhaps clarity.) Their names are
          based on their location in the `json` structure.
            + studyFactors
            + studySampleFactors
            + materialCharacteristic
            + studySampleFactors
            + AssaySampleFactors
          Out of five possible fields the user must supply three of them, one
          must be the `factorType`, another must be a `unitRef` the other must
          be a value. Either a decimal, string or reference.
          + A very special type of **Factor** is the `csvColumnIndex`
        + **Species**: The visual Bokeh models are based on a 'species'
          interpretation. That is the way in which we can theoretically
          compare values accross experiements. Each Species entry must have:
            + speciesReference: A string reference of the species.
            + stoichiometry: A decimal value representing this species
              relative ratio as compared to a samples Factors. This value may be
              used by visualizations that are concentration based.

    # TODO: Discuss comments and other parts of the json file.
            Expand on csvColumnIndex.

    **Outline of Dataflow**:

    Drupal Entry -> SQL Database -> PHP Drupal Module -> .json file ->
    isaDream DrupalNode -> idream Assays -> Bokeh Applicaitons


    '''

    def __init__(self, node_json_path):

        self.json_path = os.path.join(BASE_PATH, node_json_path)

        # Load the json file into memory.
        with open(self.json_path) as json_file:
            self.json_dict = json.load(json_file)

        # The higher tiers of metadata apply to all data (and Assay instances
        # generated by this instance.) within this class.
        self.__node_information = self.normalize_to_dataframe('nodeInformation')
        self.__study_factors = self.normalize_to_dataframe('studyFactors')
        self.__study_samples = self.normalize_to_dataframe('studySamples')
        self.__study_comments = self.normalize_to_dataframe('comments')

        # The data to be used to construct Assay instances.
        self.__study_assays = self.normalize_to_dataframe('assays')

    def normalize_to_dataframe(self, key):
        '''Reads a nested dictionary and returns a normalized pandas
        dataframe.

        '''
        # Normalize the dataframe to a list of dictionaries.
        normalized_dict = list(normalize(self.json_dict.get(key)))
        # Read the data into a pandas DataFrame.
        normalized_df = pd.io.json.json_normalize(normalized_dict)

        # Reindex this dataframe with a meaningfull name.
        idx_str = f'{key}_idx'
        normalized_df[idx_str] = [f'{idx_str}_{val}' for
                                  val in normalized_df.index.values]
        normalized_df = normalized_df.set_index(idx_str)

        # Stack the dataframe so that it will have only one column.
        normalized_df = pd.DataFrame(normalized_df.stack())
        return normalized_df

    @property
    def assays(self):
        '''Contains a list of assay dataframes associated with this instance.

        '''
        # Split the dataframe into a list of dataframes, drop the index key.
        groupby_stack = lambda node: [n[-1] for n in node.groupby(level=0)]
        return groupby_stack(self.__study_assays)

    @property
    def metadata(self):
        '''Contains all metadata above the assay level.

        This simply provides a list of the normalized dataframes that
        encapsulate the metadata of this instance.

        This property is used by the `Assay` class.

        '''
        # Split the dataframe into a list of dataframes, drop the index key.
        groupby_stack = lambda node: [n[-1] for n in node.groupby(level=0)]

        secondary_metadata = {
            'node_info': groupby_stack(self.__node_information),
            'study_factors': groupby_stack(self.__study_factors),
            'study_samples': groupby_stack(self.__study_samples),
            'study_comments': groupby_stack(self.__study_comments),
        }

        return secondary_metadata
